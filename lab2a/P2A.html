<html>
<head>
<title>Project 2A</title>
</head>

<body>
<center>
<h1>Project 2A<br>
Races and Synchronization</h1>
</center>

<h2>INTRODUCTION:</h2>
<p>
In this project, you will engage (at a low level) with a range of 
synchronization problems. Part A of the project (this part!) deals with 
conflicting read-modify-write operations on single variables and complex
data structures (an ordered linked list).  It is broken up into multiple steps:
<ul>
   <li>Part 1 - updates to a shared variable:
     <ul>
	   <li>	Write a multithreaded application (using pthreads) that 
		performs parallel updates to a shared variable.</li>
	   <li>	Demonstrate the race condition in the provided <tt>add</tt> routine, 
		and address it with different synchronization mechanisms.</li>
	   <li> Do performance instrumentation and measurement.</li>
	   <li> Analyze and explain the observed performance.</li>
     </ul>
   </li>
   <p></p>
   <li>Part 2 - updates to a shared complex data structure:
      <ul>
	   <li>	Implement the four routines described in 
	        <A href="SortedList.h">SortedList.h</a>:
		<tt>SortedList_insert, SortedList_delete,
		    SortedList_lookup, SortedList_length</tt>.
	   </li>
	   <li> Write a multi-threaded application, using pthread that performs,
		parallel updates to a sorted doubly linked list data structure 
		(using methods from the above step).</li>
	   <li>	Recognize and demonstrate the race conditions when performing 
		linked list operations, and address them with different 
		synchronization mechanisms.</li>
	   <li>Do performance instrumentation and measurement.</li>
	   <li> Analyze and explain the observed performance.</li>
      </ul>
   </li>
</ul>
Viewed from a skills (rather than problem domain) perspective, this project focuses
less on programming, and more on performance measurement and analysis.
</p>

<h2>RELATION TO READING AND LECTURES:</h2>
<p>
The basic shared counter problem was introduced in section 28.1. <br>
Mutexes, test-and-set, spin-locks, and compare-and-swap were described in (many sections of) chapter 28.<br>
Synchronization of partitioned lists was introduced in section 29.2.
</p>
<h2> PROJECT OBJECTIVES:</h2>
<ul>
   <li> primary: demonstrate the ability to recognize critical sections 
   	and address them with a variety of different mechanisms.</li>
   <li> primary: demonstrate the existence of race conditions, and efficacy of the subsequent solutions</li>
   <li> primary: experience with basic performance instrumentation, measurement and analysis</li>
</ul>
<h2> DELIVERABLES:</h2>
<p>
A single tarball (<tt>.tar.gz</tt>) containing:
<ul>

   <li> (at least) Four C source modules that compile cleanly with no errors or warnings):
   	<ul>
	   <li>	<tt>lab2_add.c</tt> ...
		a C program that implements and tests a shared variable add function, 
		implements the (below) specified command line options, and produces the 
		(below) specified output statistics.</li>
	   <li> <tt>SortedList.h</tt> ... a header file (supplied by us) describing the 
	   	interfaces for linked list operations.</li>
	   <li> <tt>SortedList.c</tt> ... a C module that implements insert, delete, lookup, 
	   	and length methods for a sorted doubly linked list 
		(described in the provided header file, including 
		correct placement of yield calls).</li>
		<P>
		You are free to implement methods beyond those described in the
		provided <tt>SortedList.h</tt>, but you cannot make any changes
		to that header file.  This header file describes the interfaces
		that you are required to implement.
		</P>
	   <li>	<tt>lab2_list.c</tt> ... a C program that implements the (below) 
	   	specified command line options and produces the (below) 
		specified output statistics.</li>
	</ul>
   </li>
   <p></p>
   <li> A <tt>Makefile</tt> to build the deliverable programs
	(<tt>lab2_add</tt> and <tt>lab2_list</tt>),
   	output, graphs, and tarball.  For your early testing you
	are free to run your program manually, but by the time you are done, 
	all of the below-described test cases should be executed, the output 
	captured, and the graphs produced automatically.  The higher level 
	targets should be:
	<ul>
	   <li> <strong>build</strong> ... (default target) compile all programs 
	     (with the <strong><tt>-Wall</tt></strong> and <strong><tt>-Wextra</tt></strong> options).
	     </li>
	   <li> <strong>tests</strong> ... run all (over 200) specified test cases to generate results in CSV 
		files. Note that the <tt>lab2_list</tt> program is expected to fail when running 
		multiple threads without synchronization.  Make sure that your 
		Makefile continues executing despite such failures (e.g. put a '-' in 
		front of commands that are expected to fail).</li>
	   <li> <strong>graphs</strong> ... 
		use <em>gnuplot(1)</em> and the supplied data reduction scripts to 
		generate the required graphs</li>
	   <li> <strong>dist</strong> ... create the deliverable tarball</li>
	   <li> <strong>clean</strong> ... delete <u>all</u> programs and output
	        created by the <tt>Makefile</tt></li>
	</ul>
   <p></p>
   <li> <tt>lab2_add.csv</tt> ... 
	containing all of your results for all of the Part-1 tests.</li>
   <li> <tt>lab2_list.csv</tt> ... 
	containing all of your results for all of the Part-2 tests.</li>
   <li> graphs (<tt>.png</tt> files), created by running <em>gnuplot(1)</em>
	on the above <tt>.csv</tt> files with the supplied data reduction scripts.
	<ul>
	   <li>	For part 1 (lab2_add):
	      <ul>
		  <li>	<tt>lab2_add-1.png</tt>
			... threads and iterations required to generate a failure 
			(with and without yields)</li>
		  <li>	<tt>lab2_add-2.png</tt> ... average time per operation 
			with and without yields.</li>
		  <li>	<tt>lab2_add-3.png</tt> ... average time per (single threaded) operation vs. 
			the number of iterations.</li>
		  <li>	<tt>lab2_add-4.png</tt> ... threads and iterations that can run successfully 
			with yields under each of the synchronization options.</li>
		  <li>	<tt>lab2_add-5.png</tt> ... average time per (protected) operation vs. 
			the number of threads.</li>
	      </ul>
	   </li>
	   <li> For part 2 (lab2_list):
		<ul>
			<li> <tt>lab2_list-1.png</tt> ... average
				 time per (single threaded) unprotected operation vs. number of 
				iterations (illustrating the correction of the per-operation cost for 
				the list length).</li>
			<li> <tt>lab2_list-2.png</tt> ... threads and iterations required to 
				generate a failure (with and without yields).</li>
			<li> <tt>lab2_list-3.png</tt> ... iterations that can run 
				(protected) without failure.</li>
			<li> <tt>lab2_list-4.png</tt> ... (length-adjusted) cost per operation vs the number of
				threads for the various synchronization options.</li>
	   	</ul>
	   </li>
	</ul>
    </li>
   <p></p>
    <li>any other scripts or files required to generate your results</li>
   <p></p>
    <li>a <tt>README</tt> text file containing:
	<ul>
		<li> descriptions of each of the included files and any other information 
		     about your submission that you would like to bring to our attention 
	 		(e.g. research, limitations, features, testing methodology).</LI>
		<li> brief (1-4 sentences per question) answers to each of the questions (below).</li>
	</ul>
    </li>
</ul>
<p></p>
<h2> PROJECT DESCRIPTION:</h2>
<h3> STUDY</h3>
<p>
To perform this assignment, you may need to study a few things:
<ul>
   <li> a more complete tutorial on <a href="https://computing.llnl.gov/tutorials/pthreads">pthreads</a>.</li>
   <li> <a href="http://man7.org/linux/man-pages/man2/clock_gettime.2.html">clock_gettime(2)</a>
   	... high resolution timers (for accurate performance data collection).</li>
   <li> <a href="http://gcc.gnu.org/onlinedocs/gcc-4.4.3/gcc/Atomic-Builtins.html">
	GCC atomic builtins</a> ... functions to directly execute atomic read-modify-write operations.</li>
   <li> <a href="https://linux.die.net/man/1/gnuplot">gnuplot(1)</a> ...  a general and powerful tool for producing a wide variety of graphs, 
	and is commonly used for organizing and reporting performance data. 
	You may need to install <em>gnuplot</em> on your system.
   </li>
   <P>
   We are providing you with sample (<em>gnuplot</em>) data reduction scripts for the first 
   parts of this assignment:
	<ul>
	   <li>	<A href="lab2_add.gp">lab2_add.gp</a></li>
	   <li>	<A href="lab2_list.gp">lab2_list.gp</a></li>
	</ul>
   </P>
   <p>
   These scripts take no arguments, read <tt>.csv</tt> files with hard-coded names
   (<tt>lab2_add.csv, lab2_list.csv</tt>) and produce graphical output
   (<tt>.png</tt> files) that correspond to your deliverable graphs.
   These scripts use <em>grep(1)</em> to extract the desired data points 
   from your <tt>lab2_add.csv</tt> and <tt>lab2_list.csv</tt> files.
   They will report errors if any of the required data points are missing
   (e.g. because you have not yet run those tests or they produced no data).
   </P>
   <P>
   If <em>gnuplot</em> is not installed in its standard location (<em>/usr/bin</em>)
   you will need to change the first line of each of these scripts to reflect
   the location where <em>gnuplot</em> is installed on the system on which you
   are running.
   </P>
   <P>
   In the next and final part of this assignment, you can use these as a basis 
   for creating your own graphing scripts.
   </P>
</ul>
<p></p>
<h3>PART 1: adds to a shared variable</h3>
<p>
Start with a basic add routine:</p>
<tt><pre>
        void add(long long *pointer, long long value) {
                long long sum = *pointer + value;
                *pointer = sum;
        }
</pre></tt>
</p>
<p>
Write a test driver program (called <strong>lab2_add</strong>) that:
<ul>
	<li> takes a parameter for the number of parallel threads (<tt>--threads=</tt>#, default 1).</li>
	<li> takes a parameter for the number of iterations (<tt>--iterations=</tt>#, default 1).</li>
	<li> initializes a (long long) counter to zero</li>
	<li> notes the (high resolution) starting time for the run (using <em>clock_gettime(3))</em></li>
	<li> starts the specified number of threads, each of which will use the above add function to
	   <ul>
		<li> add 1 to the counter the specified number of times</li>
		<li> add -1 to the counter the specified number of times</li>
		<li> exit to re-join the parent thread</li>
	   </ul>
	</li>
	<li> wait for all threads to complete, and notes the (high resolution) ending time for the run</li>
	<li> prints to stdout a comma-separated-value (CSV) record including:
	   <ul>
		<li>the name of the test (<tt>add-none</tt> for the most basic usage)</li>
		<li> the number of threads (from <tt>--threads=</tt>)</li>
		<li> the number of iterations (from <tt>--iterations=</tt>)</li>
		<li> the total number of operations performed (threads x iterations x 2, 
			the "x 2" factor because you add 1 first and then add -1)</li>
		<li> the total run time (in nanoseconds)</li>
		<li> the average time per operation (in nanoseconds).</li>
		<li> the total at the end of the run (0 if there were no conflicting updates)</li>
	   </ul>
	<li>	If bad command-line parameters are encountered or a system call fails,
		exit with a return code of one.
		If the run completes successfully, exit with a return code of zero. 
		 If any errors (other than a non-zero final count) are encountered,
		 exit with a return code of two.</li>
 </ul>
<p>
The supported command line options and expected output are illustrated below:
<tt><pre>
	% ./lab2_add --iterations=10000 --threads=10
	add-none,10,10000,200000,6574000,32,374
	%
</pre></tt>
</p>
<p>
This project calls for you to produce and graph a great deal of data.
If you install <em>gnuplot(1)</em> and append all of your test output 
to a single file (<tt>lab2_add.csv</tt> in part 1, <tt>lab2_list.csv</tt> in part 2), 
you can use our sample data reduction scripts 
(<a href="lab2_add.gp">lab2_add.gp</a> and <a href="lab2_list.gp">lab2_list.gp</a>)
to produce all of the  required data plots.
</p>
<p>
Note that each of these scripts produce <u>all</u> of the required graphs.  
Early in the process, you will not have yet generated all of the data
required for all of the graphs, and <em>gnuplot</em> will report errors
because (for some of the graphs) it found no data to plot.
</p>
<p>
Run your program for ranges of iterations 
(100, 1000, 10000, 100000) values, capture the output, and note how many 
threads and iterations it takes to (fairly consistently) result in a 
failure (non-zero sum).   
Review the results and 
(in your <tt>README</tt> file) answer the following question:
</p>

<ul>
	<strong>
	QUESTION 2.1.1 - causing conflicts:
	<ul>
	   Why does it take many iterations before errors are seen?<br>
	   Why does a significantly smaller number of iterations so seldom fail?<br>
	</ul>
	</strong>
</ul>
<p>
There are ways to cause a thread to immediately yield 
(rather than waiting for a time slice end to preempt it).  
Posix includes a <tt>sched_yield</tt> operation.  
Extend the basic add routine to more easily cause the failures:
<tt><pre>
	int opt_yield;
        void add(long long *pointer, long long value) {
                long long sum = *pointer + value;
                if (opt_yield)
                        sched_yield();
                *pointer = sum;
        }
</pre></tt>
</P>
<p>
Add a new <strong>--yield</strong> to your driver program that sets
<tt>opt_yield</tt> to 1.
If ths hoption has been specified, each line of statistics output should
begin with <tt><strong>add-yield</strong></tt>, and tests without 
synchronization should be tagged <tt><strong>add-yield-none</strong></tt>.
Re-run your tests, with yields, for ranges of threads (2,4,8,12) 
and iterations (10, 20, 40, 80, 100, 1000, 10000, 100000), capture the 
output, and plot (using the supplied data reduction script) the
(existence of) successful runs vs the number of threads and iterations.
Submit this plot as <tt>lab2_add-1.png</tt>.
Note how many iterations and threads it takes to (fairly 
consistently) result in a failure with the yield option.  
It should now be much easier to cause the failures.  
</p>
<p>
Compare the average execution time of the yield and non-yield versions a range 
threads (2, 8) and of iterations (100, 1000, 10000, 100000).   
Capture the results and plot (using the supplied data reduction script)
the time per operation vs the number of iterations, 
for yield and non-yield executions.
Submit this plot as <tt>lab2_add-2.png</tt>.
You should 
note that the <strong>--yield</strong> runs are much slower than the non-yield runs.  
Review the results and 
(in your <tt>README</tt> file) answer the following questions:
</p>
<ul>
	<strong>
	QUESTION 2.1.2 - cost of yielding:
	<ul>
		Why are the --yield runs so much slower?<br>
		Where is the additional time going?<br>
		Is it possible to get valid per-operation timings if we 
		are using the --yield option?<br>
		If so, explain how.  If not, explain why not.
	</ul>
	</strong>
</ul>
<p>
Plot (using the supplied data reduction script), for a single thread,
the average cost per operation (non-yield) as a function of the number of iterations.  
Submit this plot as <tt>lab2_add-3.png</tt>.
You should note that the average cost per operation goes down as the number of iterations goes 
up.  
Review the results and 
(in your <tt>README</tt> file) answer the following questions:
</p>
<ul>
	<strong>
	QUESTION 2.1.3 - measurement errors:
	<ul>
		Why does the average cost per operation drop with increasing iterations?<br>
	 	If the cost per iteration is a function of the number of iterations, 
		how do we know how many iterations to run (or what the "correct" cost is)?<br>
	</ul>
	</strong>
</ul>
Note: if you change your implementation to get around this problem, put that
enhancement under the control of an optional command line switch (that you
can specify in your makefile when you run subsequent tests).  But I want
to be able to run your program and see that you were able to observe this 
problem before you fixed it.
<p>
Implement three new versions of your <tt>add</tt> function:
<ul>
   <li>	one protected by a <tt>pthread_mutex</tt> enabled by a new 
   	<tt><strong>--sync=m</strong></tt> option.
	When running this test, the output statistics should begin with
	"<tt>add-m</tt>" or "<tt>add-yield-m</tt>".
	</li>
   <li>	one protected by a spin-lock, enabled by a new 
   	<tt><strong>--sync=s</strong></tt> option.
   	You will have to implement your own spin-lock operation.
	We suggest that you do this using the GCC <tt>atomic__sync_builtin</tt> functions
   	<tt>__sync_lock_test_and_set</tt> and <tt>__sync_lock_release</tt>.
	When running this test, the output statistics should begin with
	"<tt>add-s</tt>" or "<tt>add-yield-s</tt>".
	</li>
   <li> one that performs the add using the GCC <tt>atomic_sync_buildin</tt> function
   	<tt>__sync_val_compare_and_swap</tt>
	to ensure atomic updates to the shared counter, enabled by a new
   	<tt><strong>--sync=c</strong></tt> option.
	In this test case, because compare-and-swap changes the algorithm,
	the yield check should be put between the
	computation of the new sum and performing the compare-and-swap.
	When running this test, the output statistics should begin with
	"<tt>add-c</tt>" or "<tt>add-yield-c</tt>".
   	</li>
</ul>
</p>
<h4>Summary of expected tag fields</h4>
<UL>
    <li><strong>add-none</strong> ... no yield, no synchronization</li>
    <li><strong>add-m</strong> ... no yield, mutex synchronization</li>
    <li><strong>add-s</strong> ... no yield, spin-lock synchronization</li>
    <li><strong>add-c</strong> ... no yield, compare-and-swap synchronization</li>
    <li><strong>add-yield-none</strong> ... yield, no synchronization</li>
    <li><strong>add-yield-m</strong> ... yield, mutex synchronization</li>
    <li><strong>add-yield-s</strong> ... yield, spin-lock synchronization</li>
    <li><strong>add-yield-c</strong> ... yield, compare-and-swap synchronization</li>
</ul>
<P>
Use your <strong>--yield</strong> options
to confirm that, even for large numbers of threads (2, 4, 8, 12) and 
iterations (10,000 for mutexes and CAS, only 1,000 for spin locks) that 
reliably failed in the unprotected scenarios, all three of these 
serialization mechanisms eliminate the race conditions in the add 
critical section.  
[Note that we suggest a smaller number of threads/iterations when
 you test spin-lock synchronization]
</p>
<p>
Capture the output output, and plot 
(using the supplied data reduction script) the
(existence of) successful runs vs the number of threads and iterations
for each synchronization option (none, mutex, spin, compare-and-swap).
Submit this plot as <tt>lab2_add-4.png</tt>.
 </p>
<p>
Using a large enough number of iterations (e.g. 10,000) to overcome the 
issues raised in the question 2.1.3, test all four (no yield) versions 
(unprotected, mutex, spin-lock, compare-and-swap) for a range of number 
of threads (1,2,4,8,12), capture the output, and plot
(using the supplied data reduction script) the average 
time per operation (non-yield), vs the number of threads.
Submit this plot as <tt>lab2_add-5.png</tt>.
Review the results and 
(in your <tt>README</tt> file) answer the following questions:
</p>
<ul>
	<strong>
	QUESTION 2.1.4 - costs of serialization:
	<ul>
		Why do all of the options perform similarly for low numbers of threads?<br>
		Why do the three protected operations slow down as the number of threads rises?<br>
	</ul>
	</strong>
</ul>

<h3>PART 2: sorted, doubly-linked, list</h3>
<p>
Review the interface specifications for a sorted doubly linked list 
package described in the header file <A href="SortedList.h">SortedList.h</a>,
and implement all four methods in a new module named <tt><strong>SortedList.c</strong></tt>.
Note that the interface includes three software-conterolled yield options.
Identify the critical section in each of your four methods
and add calls to <tt>pthread_yield</tt> or <tt>sched_yield</tt>, controlled
by the yield options:
<ul>
	<li> in SortedList_insert if <tt>opt_yield &amp; INSERT_YIELD</tt></li>
	<li> in SortedList_delete if <tt>opt_yield &amp; DELETE_YIELD</tt></li>
	<li> in SortedList_lookup if <tt>opt_yield &amp; LOOKUP_YIELD</tt></li>
	<li> in SortedList_length if <tt>opt_yield &amp; LOOKUP_YIELD</tt></li>
</ul>
to force a switch to another thread at the critical point in each method.
</p>
<p>
Write a test driver program called <tt><strong>lab2_list</strong></tt> that:
<ul>
   <li>	takes a parameter for the number of parallel threads (<tt>--threads=</tt>#, default 1).</li>
   <li>	takes a parameter for the number of iterations (<tt>--iterations=</tt>#, default 1).</li>
   <li>	takes a parameter to enable (any combination of) optional critical section yields 
   	(<tt>--yield=[idl]</tt>,
	<tt><strong>i</strong></tt> for insert,
	<tt><strong>d</strong></tt> for delete,
	<tt><strong>l</strong></tt> for lookups).
   <li>	initializes an empty list.</li>
   <li>	creates and initializes (with random keys) the required number (threads x 
	iterations) of list elements.  Note that we do this before creating
	the threads so that this time is not included in our start-to-finish 
	measurement.  Similarly, if you free elements at the end of the test,
	do this after collecting the test execution times.</li>
   <li>	notes the (high resolution) starting time for the run
	(using <em>clock_gettime(3)</em>).</li>
   <li> starts the specified number of threads.</li>
   <li> each thread:
	<ul>
		<li> starts with a set of pre-allocated and initialized elements (<tt>--iterations=</tt>#)</li>
		<li> inserts them all into a (single shared-by-all-threads) list</li>
		<li> gets the list length</li>
		<li> looks up and deletes each of the keys it had previously inserted</li>
		<li> exits to re-join the parent thread</li>
	</ul>
   </li>
    <li> waits for all threads to complete, and notes the (high resolution) ending time for the run.</li>
    <li> checks the length of the list to confirm that it is zero.</li>
   <li> prints to stdout a comma-separated-value (CSV) record including:
	  <ul>
		<li> the name of the test, which is of the form: 
		     <strong>list-</strong><em>yieldopts</em><strong>-</strong><em>syncopts</em>: where
		     <ul>
			<li> <em>yieldopts</em> = {<strong>none, i,d,l,id,il,dl,idl</strong>}</li>
			<li> <em>syncopts</em> = {<strong>none,s,m</strong>}</li>
		     </ul>
		<li> the number of threads (from <tt>--threads=</tt>)</li>
		<li> the number of iterations (from <tt>--iterations=</tt>)</li>
		<li> the number of lists (always 1 in this project)</li>
		<li> the total number of operations performed:
		     threads x iterations x 3 (insert + lookup  + delete)</li>
		<li> the total run time (in nanoseconds) for all threads</li>
		<li> the average time per operation (in nanoseconds).</li>
	   </ul>
   </li>

   <li>	If bad arguments are encountered or a system call fails exit with a return code of one.
	If the run completes successfully, exit with a return code of zero. 
	If any inconsistencies are discovered, exit with a return code of two.</li>
</ul>
<p>
In part one, a synchronization error merely resulted in the subtracts and 
adds not balancing out.  In this part, a synchronization error is 
likely to result in a corrupted list.  If, at any time, you find 
evidence of a corrupted list (e.g. you cannot find a key that you know 
you inserted, or the list length is not zero at the end of the test), 
you should log an error message (to stderr) and exit immediately without
producing the above results record.  Note that in some cases your 
program may not detect an error, but may simply experience a 
segmentation fault.  Catch these, and log and return an error.
When you look at your test results, you should
consider any test that did not produce output to have failed.
</p>
<p>
The supported command line options and expected output are illustrated below:
<tt><pre>
	% ./lab2-list --threads=10 --iterations=1000 --yield=id
	list-id-none,10,1000,1,30000,527103247,25355
	%
</pre></tt>
<p>
Run your program with a single thread, and increasing numbers of iterations
 (10, 100, 1000, 10000, 20000), capture the output, and plot
(using the supplied data reduction script) the mean cost per operation
vs the number of iterations.
Submit this plot as <tt>lab2_list-1.png</tt>.
These results should be quite different from what 
you observed when testing your add function with increasing numbers of 
iterations. 
</p>
<p>
The time per iteration may initially go down with the number of 
iterations (as it did in part 1), but it eventually becomes linear with
the number of iterations!  This is because the time to insert into
or search a sorted list is proportional to the list length.  This 
is to be expected ... but we are primarily interested in the cost of 
serialization, and so we would like to separate the per operation costs 
from the per-element costs.  The easiest way to do this is to 
divide the cost per iteration (total / (threads * iterations)) by the 
average search distance (iterations/4).  Why iterations/4?</p>
<ul>
   <li>	Inserts take list length from 0 to iterations, 
   	and then from iterations to 0.  
	Thus, the average list length is iterations/2.</li>
   <li>	Each insert or search operation, on average, has to run 
   	through half the list, which gives us an average search distance 
	of iterations/4.</li>
</ul>
After making this correction to your reported times, 
the times per operation should (modulo start-up time) show more stable 
per operation costs.
<u>Do not change your program to make this correction!</u>.
The provided data reduction 
script graphs both the raw time per operation and the time corrected for
 the list length.
</p>
<p>
Run your program and see how many parallel threads (2,4,8,12) and 
iterations (1, 10,100,1000) it takes to fairly consistently demonstrate a 
problem.  Then run it again using various combinations of yield 
options and see how many threads (2,4,8,12) and iterations (1, 2,4,8,16,32)
it takes to fairly consistently demonstrate the problem.  Make 
sure that you can demonstrate:
<ul>
   <li> conflicts between inserts (--yield=i)</li>
   <li> conflicts between deletes (--yield=d)</li>
   <li> conflicts between inserts and lookups (--yield=il)</li>
   <li> conflicts between deletes and lookups (--yield=dl)</li>
</ul>
Capture the output, and plot (using the supplied data reduction script) the
(existence of) successful runs vs the number of threads and iterations
for non-yield and each of the above four yield combinations.
Submit this plot as <tt>lab2_list-2.png</tt>.
<p>
Add two new options to your program to call two new versions of these 
methods: 
one set of operations protected by pthread_mutexes (<tt>--sync=m</tt>),
and another protected by test-and-set spin locks (<tt>--sync=s</tt>).
Using your <tt>--yield</tt> options,
 demonstrate that either of these protections seems to eliminate all of 
the problems, even for moderate numbers of threads (12) and iterations 
(32).  [Note we limit the number of iterations because of how very
slow the spin-lock version becomes with larger numbers of threads
and iterations ... which we will get to next].
</p>
<P>
Capture the output, and plot (using the supplied data reduction script) the
(existence of) successful runs vs the number of iterations
for mutex and spin-lock protection with each of the above four yield combinations.
Submit this plot as <tt>lab2_list-3.png</tt>.
</p>
<p>
Choose an appropriate number of iterations (e.g. 1000) to overcome start-up 
costs and rerun your program without the yields for a range of # threads
(1, 2, 4, 8, 12, 16, 24).  
Capture the output, and plot (using the supplied data reduction script) the
(corrected for list length) per operation times (for each of the synchronization options: 
mutex, spin) vs the number of threads.  
Submit this plot as <tt>lab2_list-4.png</tt>.
Review the results, compare them with the analogous add timings (<tt>add-5.png</tt>) 
and (in your <tt>README</tt> file) answer the following questions:
</p>
<ul>
	<strong>
	QUESTION 2.2.1 - scalability of Mutex
	<ul>
		Compare the variation in time per mutex-protected operation vs the number of threads 
		in Part-1 (adds) and Part-2 (sorted lists).<br>
		Comment on the general shapes of the curves, and explain why they have this shape.<br>
		Comment on the relative rates of increase and differences in the shapes of the curves,
		and offer an explanation for these differences.
	</ul>
	<P>
	QUESTION 2.2.2 - scalability of spin locks
	<ul>
		Compare the variation in time per protected operation vs the number of threads 
		for list operations protected by Mutex vs Spin locks.
		Comment on the general shapes of the curves, and explain why they have this shape.<br>
		Comment on the relative rates of increase and differences in the shapes of the curves,
		and offer an explanation for these differences.
	</ul>
	</strong>
</ul>

<H2> SUMMARY OF EXIT CODES: </H2>
<ul>
	<li> 0: successful run</li>
	<li> 1: invalid command-line parameter or system call error</li>
	<li> 2: other failures</li>
</ul>

<h2> SUBMISSION: </h2>
<P>
Your <strong>README</strong> file must include lines of the form:
<ul>
	<strong>NAME:</strong> <em>your name</em><br>
	<strong>EMAIL:</strong> <em>your email</em><br>
	<strong>ID:</strong> <em>your student ID</em>
</ul>
And, if slip days are allowed on this project, and you use some:
<ul>
	<strong>SLIPDAYS:</strong> <em>your student ID</em>,<em>#days</em>
</ul>
Your name, student ID, and email address  should also appear as comments at the top
of your <tt>Makefile</tt> and each source file.
</P>
<p>
Your tarball should have a name of the form <tt>lab2a-</tt><em>studentID</em><tt>.tar.gz</tt>.<br>
You can sanity check your submission with this 
<A href="P2A_check.sh">test script</A>.<br>
<u>Projects that do not pass the test script will not be accepted!</u>
</p>
<p>
We will test it on a departmental Linux server.  
You would be well advised to test your submission on that platform before submitting it.
</p>

<h2> GRADING: </h2>
<P>
Points for this project will be awarded:
</P>
<div align="center">
<table><tbody>
<tr> <th>value</th>	<th align="left">feature</th></tr>

<tr> <td></td>		<th align="left">Packaging and build (10% total)</th></tr>
<tr> <td>2%</td>	<td>un-tars expected contents</td></tr>
<tr> <td>3%</td>	<td>clean build of correct programs w/default action (no warnings)</td></tr>
<tr> <td>3%</td>	<td>Makefile has working <tt>clean</tt>,
			    <tt>dist</tt>, <tt>test</tt> and <tt>graphs</tt> targets</td></tr>
<tr> <td>2%</td>	<td>reasonableness of <tt>README</tt> contents</td></tr>

<tr> <td></td> </tr>
<tr> <td></td>		<th align="left">Analysis (20% total)</th></tr>
<tr> <td>4%</td>	<td>General clarity of thought and understanding</td></tr>
<tr> <td>2%</td>	<td>(each) 2.1.1-2.1.4</td></tr>
<tr> <td>4%</td>	<td>(each) 2.2.1-2</td></tr>

<tr> <td></td> </tr>
<tr> <td></td>		<th align="left">Code Review (20%)</th></tr>
<tr> <td>4%</td>	<td>overall readability and reasonableness</td></tr>
<tr> <td>2%</td>	<td>add: yields correct and in appropriate places</td></tr>
<tr> <td>4%</td>	<td>list: yields correct and <u>in appropriate places</u></td></tr>
<tr> <td>2%</td>	<td>mutex correctly used for add</td></tr>
<tr> <td>2%</td>	<td>mutex correctly used for list</td></tr>
<tr> <td>2%</td>	<td>spin-lock correctly implemented and used for add</td></tr>
<tr> <td>2%</td>	<td>spin-lock correctly implemented and used for list</td></tr>
<tr> <td>2%</td>	<td>compare-and-swap correctly implemented and used for add</td></tr>

<tr> <td></td> </tr>
<tr> <td></td>		<th align="left">Add results (20% total)</th></tr>
<tr> <td>2%</td>	<td>add: threads and iterations</td></tr>
<tr> <td>2%</td>	<td>add: correct output format</td></tr>
<tr> <td>2%</td>	<td>add: reasonable time reporting</td></tr>
<tr> <td>1%</td>	<td>add: correct yield</td></tr>
<tr> <td>3%</td>	<td>add: correct mutex</td></tr>
<tr> <td>3%</td>	<td>add: correct spin</td></tr>
<tr> <td>3%</td>	<td>add: correct CAS</td></tr>
<tr> <td>4%</td>	<td>add: graphs (showed expected results)</td></tr>
<tr> <td></td> </tr>
<tr> <td></td>		<th align="left">List results (30% total)</th></tr>
<tr> <td>2%</td>	<td>list: threads and iterations</td></tr>
<tr> <td>2%</td>	<td>list: correct output format</td></tr>
<tr> <td>2%</td>	<td>list: reasonable time reporting</td></tr>
<tr> <td>6%</td>	<td>list: correct yield</td></tr>
<tr> <td>6%</td>	<td>list: correct mutex</td></tr>
<tr> <td>6%</td>	<td>list: correct spin</td></tr>
<tr> <td>6%</td>	<td>list: graphs (showed expected results)</td></tr>
</tbody></table>
</div>

<p>
Note:
 if your program does not accept the correct options or produce the 
correct output, you are likely to receive a zero for the results portion
 of your grade.  Look carefully at the sample commands and output. 
 If you have questions, ask.</p>
</body>
</html>
